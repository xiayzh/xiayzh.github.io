<!doctype html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <title>Glaucoma Screening in Fundus Image</title>

  <meta name="viewport" content="width=device-width">
</head>

<body>
  <div class="wrapper" style="font-family: Helvetica, Tahoma, Arial; width:960px; margin: 0 auto; line-height:150%">

    <section>

      <h3>
        <a id="Back-pages" class="anchor" href="#Back-pages" aria-hidden="true"><span
            class="octicon octicon-link"></span></a><a href="index.html#Project-page">
          <ud>Back to Homepage</ud>
        </a> </h3>

      <h2>
        <a id="project_title" class="anchor" href="#project_title" aria-hidden="true"><span
            class="octicon octicon-link"></span></a>Glaucoma Screening in Fundus Image
      </h2>


      <h3>Introduction:</h3>

      Glaucoma is a chronic eye disease that leads to irreversible vision loss. Since vision loss from glaucoma cannot
      be reversed, early screening and detection methods are essential to preserve vision and life quality. One major
      glaucoma screening technique is optic nerve head (ONH) assessment, which employs a binary classification to
      identify the glaucomatous and healthy subjects.
      <br><br>

      <div style="text-align: center; display: block; margin-right: auto;">
        <img src="sub_img/cover_CDR.jpg" border="0" width="400"><br></div>
      Figure: Structure of the optic nerve head. The vertical cup to disc ratio (CDR) is calculated by the ratio of
      vertical cup diameter (VCD) to vertical disc diameter (VDD), which plays an important role in the screening and
      diagnosis of glaucoma. <br>

      <br>

      <hr />

      <h3>Glaucoma Dataset:</h3>

      Due to the clinical policy, the ORIGA, SCES, and SINDI datasets cannot be released. <br>

      However, we organized the <strong>REFUGE: Retinal Fundus Glaucoma Challenge</strong> in conjunction with the
      MICCAI-OMIA Workshop 2018, including disc/cup segmentation, glaucoma screening, and localization of fovea tasks.
      This challenge provided 1200 fundus images (400 training + 400 validation + 400 test) with pixel labels. If you
      are interested, you can register and download dataset from: [<a href="https://refuge.grand-challenge.org"
        target="_blank">
        <font color="#E74C3C">
          <ud2>Link</ud2>
        </font>
      </a>]


      <br>

      <br>
      <hr />

      <h3>MNet: Multi-label Deep Network:</h3>

      In this work, we proposed a deep learning architecture, named M-Net, which solves the OD and OC segmentation
      jointly in a one-stage multi-label system. The proposed M-Net mainly consists of multi-scale input layer, U-shape
      convolutional network, side-output layer, and multi-label loss function. The multi-scale input layer constructs an
      image pyramid to achieve multiple level receptive field sizes. The U-shape convolutional network is employed as
      the main body network structure to learn the rich hierarchical representation, while the side-output layer acts as
      an early classifier that produces a companion local prediction map for different scale layers. Finally, a
      multi-label loss function is proposed to generate the final segmentation map.
      <br> <br>

      <strong>Reference:</strong><br>

      Huazhu Fu, Jun Cheng, Yanwu Xu, Damon Wing Kee Wong, Jiang Liu, and Xiaochun Cao, <strong>"Joint Optic Disc and
        Cup Segmentation Based on Multi-label Deep Network and Polar Transformation"</strong>,
      <em>IEEE Transactions on Medical Imaging (TMI)</em>, vol. 37, no. 7, pp. 1597-1605, 2018. <br>
      <a href="https://arxiv.org/abs/1801.00926" target="_blank">[PDF]</a>
      <a href="https://github.com/HzFu/MNet_DeepCDR" target="_blank">
        <font color="#ff0000">[Code]</font>
      </a>
      <br><br>

      <div style="text-align: center; display: block; margin-right: auto;">
        <img src="sub_img/framework_MNet.jpg" border="0" width="600"><br></div>
      Figure: Our M-Net architecture consists of multi-scale input layer, U-shape convolutional network, side-output
      layer, and multi-label loss function.<br>

      <br>
      <hr />

      <h3>DENet: Disc-aware Ensemble Network:</h3>

      In this work, we introduce a deep learning technique to gain additional image-relevant information, and screen
      glaucoma from the fundus image directly. Specifically, a novel Disc-aware Ensemble Network (DENet) for automatic
      glaucoma screening is proposed, which integrates the deep hierarchical context of the global fundus image and the
      local optic disc region. Four deep streams on different levels and modules are respectively considered as global
      image stream, segmentation-guided network, local disc region stream, and disc polar transformation stream.
      Finally, the output probabilities of different streams are fused as the final screening result.
      <br><br>

      <strong>Reference:</strong><br>

      Huazhu Fu, Jun Cheng, Yanwu Xu, Changqing Zhang, Damon Wing Kee Wong, Jiang Liu, Xiaochun Cao, <strong>"Disc-aware
        Ensemble Network for Glaucoma Screening from Fundus Image"</strong>,
      <em>IEEE Transactions on Medical Imaging (TMI)</em>, 2018. In press. (DOI: 10.1109/TMI.2018.2837012) <br>
      <a href="http://arxiv.org/abs/1805.07549" target="_blank">[PDF]</a>
      <a href="https://github.com/HzFu/DENet_GlaucomaScreen" target="_blank">
        <font color="#ff0000">[Code]</font>
      </a>

      <br><br>

      <div style="text-align: center; display: block; margin-right: auto;">
        <img src="sub_img/framework_DENet.jpg" border="0" width="600"><br></div>
      Figure: Architecture of our DENet, which contains four streams: global image stream produces the result based on
      the global fundus image; the segmentation guided network localizes the optic disc region and generates a detection
      output embedded the disc-segmentation representation; disc region stream works on disc region cropped by disc
      segmentation map from segmentation-guided network; disc polar stream transfers the disc region image into the
      polar coordinate system. The combination of these four streams is fused as the final glaucoma screening result.
      <br>

      <br>
      <hr />



      <h3>Other Related Works:</h3>

      <ol>

        <li>Huazhu Fu, Yanwu Xu, Stephen Lin, Damon Wing Kee Wong, Jiang Liu, <strong>"DeepVessel: Retinal Vessel
            Segmentation via Deep Learning and Conditional Random Field"</strong>,
          in <em>International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</em>,
          2016, pp. 132-139. <br>
          <a href="http://dx.doi.org/10.1007/978-3-319-46723-8_16" class="user-mention" target="_blank">[PDF]</a> <a
            href="proj_deepvessel.html">[Project]</a></li>

        <li>Huazhu Fu, Yanwu Xu, Stephen Lin, Xiaoqin Zhang, Damon Wing Kee Wong, Jiang Liu, Alejandro F. Frangi, Mani
          Baskaran, Tin Aung, <strong>"Segmentation and Quantification for Angle-Closure Glaucoma Assessment in Anterior
            Segment OCT"</strong>,
          <em>IEEE Transactions on Medical Imaging (TMI)</em>, vol. 36, no. 9, pp. 1930-1938, 2017. <br>
          <a href="https://doi.org/10.1109/TMI.2017.2703147" target="_blank">[PDF]</a> <a
            href="proj_glaucoma_asoct.html" target="_blank">[Project]</a></li>

      </ol>

      <br>


    </section>

  </div>
</body>

</html>